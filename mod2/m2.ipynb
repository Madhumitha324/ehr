{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8a2ed5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient sheet loaded: (300, 8)\n",
      "Images mapped: (297, 2)\n",
      "Saved meta_df.csv successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>Stroke_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stroke_classification\\Haemorrhagic\\Patient_003...</td>\n",
       "      <td>Haemorrhagic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stroke_classification\\Haemorrhagic\\Patient_004...</td>\n",
       "      <td>Haemorrhagic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stroke_classification\\Haemorrhagic\\Patient_012...</td>\n",
       "      <td>Haemorrhagic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stroke_classification\\Haemorrhagic\\Patient_013...</td>\n",
       "      <td>Haemorrhagic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stroke_classification\\Haemorrhagic\\Patient_028...</td>\n",
       "      <td>Haemorrhagic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path   Stroke_Type\n",
       "0  Stroke_classification\\Haemorrhagic\\Patient_003...  Haemorrhagic\n",
       "1  Stroke_classification\\Haemorrhagic\\Patient_004...  Haemorrhagic\n",
       "2  Stroke_classification\\Haemorrhagic\\Patient_012...  Haemorrhagic\n",
       "3  Stroke_classification\\Haemorrhagic\\Patient_013...  Haemorrhagic\n",
       "4  Stroke_classification\\Haemorrhagic\\Patient_028...  Haemorrhagic"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Your patient CSV file\n",
    "patient_csv_path = \"patient.csv\"\n",
    "\n",
    "# Load patient metadata\n",
    "patients = pd.read_csv(patient_csv_path)\n",
    "print(\"Patient sheet loaded:\", patients.shape)\n",
    "\n",
    "# Folder containing medical images\n",
    "base_folder = \"Stroke_classification\"\n",
    "\n",
    "# Map folder names to labels\n",
    "label_map = {\n",
    "    \"Haemorrhagic\": \"Haemorrhagic\",\n",
    "    \"Ischemic\": \"Ischemic\",\n",
    "    \"Normal\": \"Normal\"\n",
    "}\n",
    "\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for folder in os.listdir(base_folder):\n",
    "    full_path = os.path.join(base_folder, folder)\n",
    "    \n",
    "    if os.path.isdir(full_path):\n",
    "        for img in os.listdir(full_path):\n",
    "            if img.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                image_paths.append(os.path.join(full_path, img))\n",
    "                labels.append(folder)\n",
    "\n",
    "# Create DataFrame\n",
    "meta_df = pd.DataFrame({\n",
    "    \"image_path\": image_paths,\n",
    "    \"Stroke_Type\": labels\n",
    "})\n",
    "\n",
    "print(\"Images mapped:\", meta_df.shape)\n",
    "\n",
    "# SAVE for Module 2 usage\n",
    "meta_df.to_csv(\"meta_df.csv\", index=False)\n",
    "\n",
    "print(\"Saved meta_df.csv successfully!\")\n",
    "meta_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1beda660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          image_path   Stroke_Type\n",
      "0  Stroke_classification\\Haemorrhagic\\Patient_003...  Haemorrhagic\n",
      "1  Stroke_classification\\Haemorrhagic\\Patient_004...  Haemorrhagic\n",
      "2  Stroke_classification\\Haemorrhagic\\Patient_012...  Haemorrhagic\n",
      "3  Stroke_classification\\Haemorrhagic\\Patient_013...  Haemorrhagic\n",
      "4  Stroke_classification\\Haemorrhagic\\Patient_028...  Haemorrhagic\n"
     ]
    }
   ],
   "source": [
    "meta_df = pd.read_csv(\"meta_df.csv\")\n",
    "print(meta_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aadfef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "701dec3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhancer model ready.\n"
     ]
    }
   ],
   "source": [
    "class EnhancerNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EnhancerNet, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 2, stride=2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(32, 1, 2, stride=2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "enhancer_model = EnhancerNet()\n",
    "print(\"Enhancer model ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66678f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdba5f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_image(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    img_tensor = transform(img).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        enhanced_tensor = enhancer_model(img_tensor)\n",
    "\n",
    "    enhanced_np = enhanced_tensor.squeeze().numpy()\n",
    "\n",
    "    return enhanced_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51e65712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing enhancement on: Stroke_classification\\Haemorrhagic\\Patient_003.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.03331919, 0.03562793, 0.03521232, ..., 0.032878  , 0.03395087,\n",
       "        0.03207485],\n",
       "       [0.03430567, 0.03643325, 0.03536519, ..., 0.03072106, 0.0320534 ,\n",
       "        0.02790923],\n",
       "       [0.03398917, 0.03642219, 0.03472058, ..., 0.0314109 , 0.03017635,\n",
       "        0.02963807],\n",
       "       ...,\n",
       "       [0.03073784, 0.03140718, 0.03311124, ..., 0.02952928, 0.0321618 ,\n",
       "        0.02709967],\n",
       "       [0.02985315, 0.03209171, 0.03093318, ..., 0.0309866 , 0.02966819,\n",
       "        0.02900667],\n",
       "       [0.02977415, 0.02828303, 0.02988974, ..., 0.02625975, 0.02831389,\n",
       "        0.02745545]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_path = meta_df.iloc[0][\"image_path\"]\n",
    "print(\"Testing enhancement on:\", sample_path)\n",
    "\n",
    "enhance_image(sample_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c9e4ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Loss: 3.7779\n",
      "Epoch 2/5 - Loss: 0.6465\n",
      "Epoch 3/5 - Loss: 0.5709\n",
      "Epoch 4/5 - Loss: 0.5280\n",
      "Epoch 5/5 - Loss: 0.5025\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(enhancer_model.parameters(), lr=0.001)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "def train_enhancement(epochs=3):\n",
    "    enhancer_model.train()\n",
    "\n",
    "    for e in range(epochs):\n",
    "        total_loss = 0\n",
    "\n",
    "        for idx, row in meta_df.iterrows():\n",
    "            img_path = row[\"image_path\"]\n",
    "\n",
    "            try:\n",
    "                img = Image.open(img_path)\n",
    "                img = transform(img).unsqueeze(0)\n",
    "\n",
    "                noise = torch.randn_like(img) * 0.1\n",
    "                noisy_img = img + noise\n",
    "\n",
    "                out = enhancer_model(noisy_img)\n",
    "                loss = loss_fn(out, img)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        print(f\"Epoch {e+1}/{epochs} - Loss: {total_loss:.4f}\")\n",
    "\n",
    "train_enhancement(epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3c2f604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"Enhanced_Output\", exist_ok=True)\n",
    "\n",
    "def save_all_enhanced():\n",
    "    for idx, row in meta_df.iterrows():\n",
    "        img_path = row[\"image_path\"]\n",
    "        enhanced = enhance_image(img_path)\n",
    "\n",
    "        # Convert float â†’ uint8 (0-255)\n",
    "        enhanced_img = (enhanced * 255).astype(\"uint8\")\n",
    "\n",
    "        out_path = f\"Enhanced_Output/enh_{idx}.png\"\n",
    "        cv2.imwrite(out_path, enhanced_img)\n",
    "\n",
    "    print(\"All enhanced images saved in Enhanced_Output/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c79ffa0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All enhanced images saved in Enhanced_Output/\n"
     ]
    }
   ],
   "source": [
    "save_all_enhanced()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
